import { defineStore } from "pinia";
import type { Ref } from "vue";

export const useServiceCollectionLogStore = defineStore(
  "service_collection_log",
  () => {
    const { $api } = useNuxtApp();

    const collectionLogData: Ref<object> = ref({});
    let serviceId = "";

    const setServiceId = (id: string) => {
      serviceId = id;
    };
    const getCollectionLogData = async () => {
      // const data: any = await $api(
      //   `http://192.168.105.26:8585/api/v1/services/ingestionPipelines/logs/${serviceId}/last?after=`,
      // );
      const data = {
        log: "199c25dd00eb\n*** Found local files:\n***   * /opt/airflow/logs/dag_id=75949367-2c88-4eed-9466-ae7114fdc25b/run_id=scheduled__2024-08-13T00:00:00+00:00/task_id=profiler_task/attempt=1.log\n[2024-08-14T00:00:12.338+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: 75949367-2c88-4eed-9466-ae7114fdc25b.profiler_task scheduled__2024-08-13T00:00:00+00:00 [queued]>\n[2024-08-14T00:00:12.355+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: 75949367-2c88-4eed-9466-ae7114fdc25b.profiler_task scheduled__2024-08-13T00:00:00+00:00 [queued]>\n[2024-08-14T00:00:12.356+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 1\n[2024-08-14T00:00:12.384+0000] {taskinstance.py:1382} INFO - Executing <Task(CustomPythonOperator): profiler_task> on 2024-08-13 00:00:00+00:00\n[2024-08-14T00:00:12.399+0000] {standard_task_runner.py:57} INFO - Started process 561072 to run task\n[2024-08-14T00:00:12.411+0000] {standard_task_runner.py:84} INFO - Running: ['airflow', 'tasks', 'run', '75949367-2c88-4eed-9466-ae7114fdc25b', 'profiler_task', 'scheduled__2024-08-13T00:00:00+00:00', '--job-id', '2203', '--raw', '--subdir', 'DAGS_FOLDER/75949367-2c88-4eed-9466-ae7114fdc25b.py', '--cfg-path', '/tmp/tmpt9jiv7rk']\n[2024-08-14T00:00:12.413+0000] {standard_task_runner.py:85} INFO - Job 2203: Subtask profiler_task\n[2024-08-14T00:00:12.516+0000] {task_command.py:416} INFO - Running <TaskInstance: 75949367-2c88-4eed-9466-ae7114fdc25b.profiler_task scheduled__2024-08-13T00:00:00+00:00 [running]> on host 199c25dd00eb\n[2024-08-14T00:00:12.634+0000] {taskinstance.py:1662} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='admin' AIRFLOW_CTX_DAG_ID='75949367-2c88-4eed-9466-ae7114fdc25b' AIRFLOW_CTX_TASK_ID='profiler_task' AIRFLOW_CTX_EXECUTION_DATE='2024-08-13T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-08-13T00:00:00+00:00'\n[2024-08-14T00:00:12.681+0000] {server_mixin.py:75} INFO - OpenMetadata client running with Server version [1.4.0] and Client version [1.4.0.1]\n[2024-08-14T00:00:12.900+0000] {metadata.py:107} INFO - Starting profiler for service test_df3:mysql\n[2024-08-14T00:00:14.751+0000] {test_connections.py:215} INFO - Test connection results:\n[2024-08-14T00:00:14.752+0000] {test_connections.py:216} INFO - failed=[] success=[\"'CheckAccess': Pass\", \"'GetSchemas': Pass\", \"'GetTables': Pass\", \"'GetViews': Pass\"] warning=[]\n[2024-08-14T00:00:14.792+0000] {status.py:76} WARNING - Error listing source and entities for database due to [Can't instantiate abstract class ProfilerSource with abstract method create_storage_profiler_interface]\n[2024-08-14T00:00:14.982+0000] {taskinstance.py:1937} ERROR - Task failed with exception\nTraceback (most recent call last):\n  File \"/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/python.py\", line 192, in execute\n    return_value = self.execute_callable()\n  File \"/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/python.py\", line 209, in execute_callable\n    return self.python_callable(*self.op_args, **self.op_kwargs)\n  File \"/home/airflow/.local/lib/python3.10/site-packages/openmetadata_managed_apis/workflows/ingestion/profiler.py\", line 51, in profiler_workflow\n    workflow.raise_from_status()\n  File \"/home/airflow/.local/lib/python3.10/site-packages/metadata/workflow/workflow_status_mixin.py\", line 125, in raise_from_status\n    raise err\n  File \"/home/airflow/.local/lib/python3.10/site-packages/metadata/workflow/workflow_status_mixin.py\", line 122, in raise_from_status\n    self.raise_from_status_internal(raise_warnings)\n  File \"/home/airflow/.local/lib/python3.10/site-packages/metadata/workflow/ingestion.py\", line 150, in raise_from_status_internal\n    raise WorkflowExecutionError(\nmetadata.config.common.WorkflowExecutionError: OpenMetadata Service reported errors: OpenMetadata Service Summary: [0 Records, [0 Updated Records, 0 Warnings, 1 Errors, 0 Filtered]\n[2024-08-14T00:00:15.005+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=75949367-2c88-4eed-9466-ae7114fdc25b, task_id=profiler_task, execution_date=20240813T000000, start_date=20240814T000012, end_date=20240814T000015\n[2024-08-14T00:00:15.006+0000] {common.py:302} INFO - Sending failed status from callback...\n[2024-08-14T00:00:15.027+0000] {server_mixin.py:75} INFO - OpenMetadata client running with Server version [1.4.0] and Client version [1.4.0.1]\n[2024-08-14T00:00:15.028+0000] {common.py:308} INFO - Sending status to Ingestion Pipeline test_df3.75949367-2c88-4eed-9466-ae7114fdc25b\n[2024-08-14T00:00:15.144+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 2203 for task profiler_task (OpenMetadata Service reported errors: OpenMetadata Service Summary: [0 Records, [0 Updated Records, 0 Warnings, 1 Errors, 0 Filtered]; 561072)\n[2024-08-14T00:00:15.166+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 1\n[2024-08-14T00:00:15.196+0000] {taskinstance.py:2778} INFO - 0 downstream tasks scheduled from follow-on schedule check\n",
      };
      collectionLogData.value = data;
    };

    return { setServiceId, collectionLogData, getCollectionLogData };
  },
);
